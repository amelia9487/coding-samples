{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini-project 1\n",
    "\n",
    "__Goal:__ The goal of this assignment is to conduct a study that compares the performance of various classification algorithms on a variety of datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Datasets:__ The folder data contains 98 publicly available datasets from the UCI machine learning repository ([link](http://archive.ics.uci.edu/ml/index.php)). These datasets were collected and converted to a standard format by Dunn and Bertsimas (for more details see [link1](https://github.com/JackDunnNZ/uci-data) and [link2](http://jack.dunn.nz/papers/OptimalClassificationTrees.pdf)):\n",
    "* Each dataset is stored in a separate folder\n",
    "* Each folder contains a datafile and the configuration file config.ini specifying the data format\n",
    "- Data files are stored in csv format and their names either end with \".orig\" or at \".custom\". If both files exist in a folder, use the file ending with \".custom\"\n",
    "- Each config.ini file contains information about a dataset: \n",
    "    - separator: the character used to separate columns in the respective csv file\n",
    "    - header_lines: the number of rows to be skipped in the datafile as these contain some information about the file but not data\n",
    "    - target_index: the column number of the output variable\n",
    "    - value_indices: the column numbers of the input variables\n",
    "    - categoric_indices: column numbers of categorical data\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Remarks__:\n",
    "1. Notice that column numbering in the configuration files begins with 1 (versus 0 in Python)\n",
    "2. You may use the package [configparser](https://docs.python.org/3.7/library/configparser.html) to read and parse config.ini files\n",
    "3. The character \"?\" denotes a null value. After reading a data file, you may drop all lines that contain null values.\n",
    "4. Out of the 98 datasets, use only the 54 datasets whose name is stored in the file \"datasets_selection\".\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Assignment__: compare the performance of the following classification algorithms on the 54 datasets: \n",
    "- Support vector machine, \n",
    "- Logistic Regression, \n",
    "- K-nearest neighbors, \n",
    "- Decision trees, \n",
    "- Quadratic discriminant analysis, \n",
    "- Random forests, and \n",
    "- AdaBoost\n",
    "\n",
    "\n",
    "Submit your solution as a jupyter notebook and include in your submission other files that may be needed to replicate your analysis. In addition, submit a report (at most 4 pages long) that discusses your methodology, key findings, as well as the limitations of your analysis. Compare the use of ML methods in this project against typical ML applications. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Tip:__ Start early. The assignment requires substantial amount of files processing prior to running the learning algorithms and analyzing the results. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = pd.read_csv('datasets_selection',header=None)\n",
    "\n",
    "for i in range(0, 54):\n",
    "    d[0][i] = d[0][i][:-5]\n",
    "dflist = d[0].tolist()\n",
    "len(dflist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=!ls data\n",
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_selection = []\n",
    "for i in dflist:\n",
    "    for j in a:\n",
    "        if i == j:\n",
    "            dataset_selection.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_selection.append('breast-cancer-wisconsin-original')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# return the dataset file path\n",
    "import os\n",
    "\n",
    "def loadDataset(folder):\n",
    "    files = os.listdir('data/' + folder)\n",
    "    custom = [file for file in files if '.orig.custom' in file]\n",
    "    orig = [file for file in files if '.orig' in file]\n",
    "    if len(custom) > 0:\n",
    "        return ('data/' + folder + '/' + custom[0])\n",
    "    elif len(orig) > 0:\n",
    "        return ('data/' + folder + '/' + orig[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pre-process the files with whitespace\n",
    "def whitespace(folder):\n",
    "    rows = open(folder, 'r', encoding='utf-8').read().split('\\n')\n",
    "    with open(folder, 'w') as f:\n",
    "        for r in rows:\n",
    "            r = str(r.lstrip())\n",
    "            l = r.split(' ')\n",
    "            if '' in l: l = list(filter(lambda a: a != '', l))\n",
    "            r = ' '.join(l)\n",
    "            f.write(r + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# return the dataset as a dataframe format\n",
    "import pandas as pd\n",
    "import configparser\n",
    "\n",
    "def configure(folder):\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read('data/'+ folder + '/config.ini')\n",
    "    \n",
    "    flag = True\n",
    "    if config['info']['separator'] == 'comma':\n",
    "        sep = ','\n",
    "        flag = False\n",
    "    elif config['info']['separator'] == ';':\n",
    "        sep = ';'\n",
    "        flag = False\n",
    "    elif config['info']['separator'] == '':\n",
    "        sep = '\\s*\\^'\n",
    "    \n",
    "    if flag == True:\n",
    "        if config['info']['header_lines'] == '0':\n",
    "            return pd.read_csv(loadDataset(folder), header = None, na_values = {'?', 'NaN'}, delim_whitespace=True).dropna(how='any')\n",
    "        else:\n",
    "            i = config['info']['header_lines']\n",
    "            return pd.read_csv(loadDataset(folder), skiprows = int(i), header = None, na_values = {'?', 'NaN'}, delim_whitespace=True).dropna(how = 'any')\n",
    "    else:\n",
    "        if config['info']['header_lines'] == '0':\n",
    "            return pd.read_csv(loadDataset(folder), sep = sep, header = None, na_values = {'?', 'NaN'}, engine='python').dropna(how='any')\n",
    "        else:\n",
    "            i = config['info']['header_lines']\n",
    "            return pd.read_csv(loadDataset(folder), sep = sep, skiprows = int(i), header = None, na_values = {'?', 'NaN'}, engine='python').dropna(how = 'any')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# return target_index\n",
    "def label(folder):\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read('data/'+ folder + '/config.ini')\n",
    "    target = int(config['info']['target_index'])-1\n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data cleaning pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin): \n",
    "    def __init__(self, attibute_names):\n",
    "        self.attibute_names = attibute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return(self)\n",
    "    def transform(self, X): \n",
    "        return(X[self.attibute_names].values)\n",
    "\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "%run CategoricalEncoder.py\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "def prepared(folder):\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read('data/'+ folder + '/config.ini')\n",
    "    num = config['info']['value_indices'].split(',')\n",
    "    cat = config['info']['categoric_indices'].split(',')\n",
    "    \n",
    "    # numerical attributes' pipeline\n",
    "    num_attributes = [int(i)-1 for i in num if i not in cat]\n",
    "    num_pipeline = Pipeline([\n",
    "        ('selector',DataFrameSelector(num_attributes)),\n",
    "        ('imputer',Imputer(strategy=\"median\")),\n",
    "        ('std_scaler', StandardScaler()),])\n",
    "\n",
    "    # categorical attributes' pipeline\n",
    "    cat_attributes = [int(i)-1 for i in cat if i != '']\n",
    "    cat_pipeline = Pipeline([\n",
    "        ('selector',DataFrameSelector(cat_attributes)),\n",
    "        ('label_binarizer',CategoricalEncoder(encoding=\"onehot-dense\")),])\n",
    "    \n",
    "    # full pipeline\n",
    "    if len(num_attributes) == 0:\n",
    "        full_pipeline = FeatureUnion(transformer_list=[\n",
    "        ('cat_pipeline',cat_pipeline)])\n",
    "    elif len(cat_attributes) == 0:\n",
    "        full_pipeline = FeatureUnion(transformer_list=[\n",
    "        ('num_pipeline',num_pipeline)])\n",
    "    else:\n",
    "        full_pipeline = FeatureUnion(transformer_list=[\n",
    "            ('num_pipeline',num_pipeline),\n",
    "            ('cat_pipeline',cat_pipeline),])\n",
    "\n",
    "    \n",
    "    df = configure(folder)\n",
    "    for i in range(len(df.columns)):\n",
    "        encoder = LabelEncoder()\n",
    "        df[i] = encoder.fit_transform(df[i]) # single command for fit and transform \n",
    "    df_Y = df[label(folder)]\n",
    "    del df[label(folder)]\n",
    "    df_X = df\n",
    "    return (full_pipeline.fit_transform(df_X), df_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function Randomforest\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "def Random_forest():\n",
    "    parameters = {'max_features': ('auto', 'sqrt'), 'n_estimators': [100, 150], 'max_depth': [15, 30]}\n",
    "    rf = RandomForestClassifier()\n",
    "    clf = GridSearchCV(rf, parameters)\n",
    "    clf.fit(train_X, train_Y)\n",
    "    rf_predictions = clf.predict(test_X)\n",
    "    rf_mse = mean_squared_error(test_Y, rf_predictions)\n",
    "    rf_rmse = np.sqrt(rf_mse)\n",
    "    print(\"The rmse of Random forest is: \",rf_rmse)\n",
    "    n = len(test_Y)\n",
    "    accuracy = sum(rf_predictions==test_Y)/n\n",
    "    print(\"The accuracy of Random forest is: \",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function QDA\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "def QDA():\n",
    "    clf = QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0)\n",
    "    clf.fit(train_X, train_Y)\n",
    "    qda_predictions = clf.predict(test_X)\n",
    "    qda_mse = mean_squared_error(test_Y, qda_predictions)\n",
    "    qda_rmse = np.sqrt(qda_mse)\n",
    "    print(\"The rmse of QDA is: \",qda_rmse)\n",
    "    n = len(test_Y)\n",
    "    accuracy = sum(qda_predictions==test_Y)/n\n",
    "    print(\"The accuracy of QDA is: \",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "def KNN():\n",
    "    parameters = {'n_neighbors': [3, 5, 7], 'weights': ('distance', 'uniform')}\n",
    "    knn = KNeighborsClassifier()\n",
    "    clf = GridSearchCV(knn, parameters)\n",
    "    clf.fit(train_X, train_Y)\n",
    "    knn_predictions = clf.predict(test_X)\n",
    "    knn_mse = mean_squared_error(test_Y, knn_predictions)\n",
    "    knn_rmse = np.sqrt(knn_mse)\n",
    "    print(\"The rmse of KNN is: \",knn_rmse)\n",
    "    n = len(test_Y)\n",
    "    accuracy = sum(knn_predictions==test_Y)/n\n",
    "    print(\"The accuracy of KNN is: \",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function adaboost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "def adaboost():\n",
    "    parameters = {'learning_rate': [0.05, 0.1, 0.2], 'n_estimators': [40, 50, 60, 70]} \n",
    "    ada = AdaBoostClassifier()\n",
    "    clf = GridSearchCV(ada, parameters)\n",
    "    clf.fit(train_X,train_Y)\n",
    "    ada_predictions = clf.predict(test_X)\n",
    "    ada_mse = mean_squared_error(test_Y,ada_predictions)\n",
    "    ada_rmse = np.sqrt(ada_mse)\n",
    "    print(\"The rmse of Adaboost is: \",ada_rmse)\n",
    "    n = len(test_Y)\n",
    "    accuracy = sum(ada_predictions==test_Y)/n\n",
    "    print(\"The accuracy of adaboost is: \",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression  \n",
    "from sklearn.metrics import mean_squared_error\n",
    "def LogisticRegression():\n",
    "    from sklearn.linear_model import LogisticRegression \n",
    "    parameters = {'C': [10, 100, 1000, 10**4], 'fit_intercept': (True, False), 'solver': ('liblinear', 'lbfgs', 'newton-cg')}\n",
    "    lr = LogisticRegression()\n",
    "    clf = GridSearchCV(lr, parameters) \n",
    "    clf.fit(train_X, train_Y)\n",
    "    lr_predictions = clf.predict(test_X)\n",
    "    lr_mse = mean_squared_error(test_Y, lr_predictions)\n",
    "    lr_rmse = np.sqrt(lr_mse)\n",
    "    print(\"The rmse of Logistic regression is: \",lr_rmse)\n",
    "    n = len(test_Y)\n",
    "    accuracy = sum(lr_predictions==test_Y)/n\n",
    "    print(\"The accuracy of Logistic regression is: \",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function Decision Tree\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "def DecisionTree():\n",
    "    clf = DecisionTreeRegressor()\n",
    "    clf.fit(train_X, train_Y)\n",
    "    dt_predictions = clf.predict(test_X)\n",
    "    dt_mse = mean_squared_error(test_Y, dt_predictions)\n",
    "    dt_rmse = np.sqrt(dt_mse)\n",
    "    print(\"The rmse of Decision Tree is: \",dt_rmse)\n",
    "    n = len(test_Y)\n",
    "    accuracy = sum(dt_predictions==test_Y)/n\n",
    "    print(\"The accuracy of Decision Tree is: \",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function SVM\n",
    "from sklearn import svm\n",
    "def SVM():\n",
    "    parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10, 100, 1000]}\n",
    "    svc = svm.SVC()\n",
    "    clf = GridSearchCV(svc, parameters)\n",
    "    clf.fit(train_X, train_Y)\n",
    "    svm_predictions = clf.predict(test_X)\n",
    "    svm_mse = mean_squared_error(test_Y, svm_predictions)\n",
    "    svm_rmse = np.sqrt(svm_mse)\n",
    "    print(\"The rmse of SVM is: \",svm_rmse)\n",
    "    n = len(test_Y)\n",
    "    accuracy = sum(svm_predictions==test_Y)/n\n",
    "    print(\"The accuracy of svm is: \",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "hayes-roth\n"
     ]
    }
   ],
   "source": [
    "x = int(input())\n",
    "print(dataset_selection[x])\n",
    "folder = dataset_selection[x]\n",
    "\n",
    "# clean the whitespace\n",
    "whitespace(loadDataset(folder))\n",
    "\n",
    "# data cleaning\n",
    "df_X, df_Y = prepared(folder)\n",
    "\n",
    "# split the training and test dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_X, test_X = train_test_split(df_X, test_size=0.2, random_state=1)\n",
    "train_Y, test_Y = train_test_split(df_Y, test_size=0.2, random_state=1)\n",
    "\n",
    "\n",
    "# use ravel() to transform train_Y, train_X\n",
    "train_Y=train_Y.values.ravel()\n",
    "test_Y =test_Y.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rmse of Random forest is:  0.38490017946\n",
      "The accuracy of Random forest is:  0.851851851852\n",
      "The rmse of QDA is:  0.881917103688\n",
      "The accuracy of QDA is:  0.444444444444\n",
      "The rmse of KNN is:  0.981306762925\n",
      "The accuracy of KNN is:  0.592592592593\n",
      "The rmse of Adaboost is:  0.0\n",
      "The accuracy of adaboost is:  1.0\n",
      "The rmse of Logistic regression is:  0.902670933848\n",
      "The accuracy of Logistic regression is:  0.407407407407\n",
      "The rmse of Decision Tree is:  0.160375074775\n",
      "The accuracy of Decision Tree is:  0.925925925926\n",
      "The rmse of SVM is:  0.693888666489\n",
      "The accuracy of svm is:  0.740740740741\n"
     ]
    }
   ],
   "source": [
    "# show the result of seven algorithom's rmse and accuracy\n",
    "Random_forest()\n",
    "QDA()\n",
    "KNN()\n",
    "adaboost()\n",
    "LogisticRegression()\n",
    "DecisionTree()\n",
    "SVM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>132.000000</td>\n",
       "      <td>1.320000e+02</td>\n",
       "      <td>1.320000e+02</td>\n",
       "      <td>1.320000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.410780e-18</td>\n",
       "      <td>-6.055762e-17</td>\n",
       "      <td>7.149163e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.003810</td>\n",
       "      <td>1.003810e+00</td>\n",
       "      <td>1.003810e+00</td>\n",
       "      <td>1.003810e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.224745</td>\n",
       "      <td>-1.010753e+00</td>\n",
       "      <td>-1.010753e+00</td>\n",
       "      <td>-1.010753e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.224745</td>\n",
       "      <td>-1.010753e+00</td>\n",
       "      <td>-1.010753e+00</td>\n",
       "      <td>-1.010753e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.813110e-02</td>\n",
       "      <td>4.813110e-02</td>\n",
       "      <td>4.813110e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.224745</td>\n",
       "      <td>4.813110e-02</td>\n",
       "      <td>4.813110e-02</td>\n",
       "      <td>4.813110e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.224745</td>\n",
       "      <td>2.165899e+00</td>\n",
       "      <td>2.165899e+00</td>\n",
       "      <td>2.165899e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1             2             3\n",
       "count  132.000000  1.320000e+02  1.320000e+02  1.320000e+02\n",
       "mean     0.000000  8.410780e-18 -6.055762e-17  7.149163e-18\n",
       "std      1.003810  1.003810e+00  1.003810e+00  1.003810e+00\n",
       "min     -1.224745 -1.010753e+00 -1.010753e+00 -1.010753e+00\n",
       "25%     -1.224745 -1.010753e+00 -1.010753e+00 -1.010753e+00\n",
       "50%      0.000000  4.813110e-02  4.813110e-02  4.813110e-02\n",
       "75%      1.224745  4.813110e-02  4.813110e-02  4.813110e-02\n",
       "max      1.224745  2.165899e+00  2.165899e+00  2.165899e+00"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(df_X).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
